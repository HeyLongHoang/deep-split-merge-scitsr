{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2 as cv\n",
    "import random\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: change the path to your dataset\n",
    "OG_SCITSR_PATH = '/Users/longhoang/Developer/table-recognition/data/SciTSR'\n",
    "\n",
    "OG_SCITSR_TRAIN = os.path.join(OG_SCITSR_PATH, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: change the path to the directory for the new partitioned dataset\n",
    "NEW_SCITSR_DIR = '/Users/longhoang/Developer/table-recognition/data'\n",
    "\n",
    "NEW_SCITSR_ROOT = os.path.join(NEW_SCITSR_DIR, 'scitsr-split-train')\n",
    "NEW_SCITSR_TRAIN = os.path.join(NEW_SCITSR_ROOT, 'train')\n",
    "NEW_SCITSR_VAL = os.path.join(NEW_SCITSR_ROOT, 'val')\n",
    "\n",
    "os.makedirs(NEW_SCITSR_TRAIN, exist_ok=True)\n",
    "os.makedirs(NEW_SCITSR_VAL, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['img', 'label']\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(os.path.join(NEW_SCITSR_TRAIN, folder), exist_ok=True)\n",
    "    os.makedirs(os.path.join(NEW_SCITSR_VAL, folder), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_name_from_path(img_path):\n",
    "    return os.path.splitext(os.path.basename(img_path))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n"
     ]
    }
   ],
   "source": [
    "OG_SCITSR_IMG = os.path.join(OG_SCITSR_TRAIN, 'img')\n",
    "\n",
    "OG_IMG_PATHS = sorted([os.path.join(OG_SCITSR_IMG, f) for f in os.listdir(OG_SCITSR_IMG )])\n",
    "VALID_IMG_PATHS = [p for p in OG_IMG_PATHS if cv.imread(p) is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11971"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(VALID_IMG_PATHS) # same number of valid images as the other notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(VALID_IMG_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1971)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs_paths = VALID_IMG_PATHS[:10000]\n",
    "val_imgs_paths = VALID_IMG_PATHS[10000:]\n",
    "len(train_imgs_paths), len(val_imgs_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy images to the new train and validation folder\n",
    "NEW_TRAIN_IMG_DIR = os.path.join(NEW_SCITSR_TRAIN, 'img')\n",
    "for img_path in train_imgs_paths:\n",
    "    img_name = os.path.basename(img_path)\n",
    "    dest_path = os.path.join(NEW_TRAIN_IMG_DIR, img_name)\n",
    "    shutil.copy2(img_path, dest_path)\n",
    "\n",
    "NEW_VAL_IMG_DIR = os.path.join(NEW_SCITSR_VAL, 'img')\n",
    "for img_path in val_imgs_paths:\n",
    "    img_name = os.path.basename(img_path)\n",
    "    dest_path = os.path.join(NEW_VAL_IMG_DIR, img_name)\n",
    "    shutil.copy2(img_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1971)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_len = len(os.listdir(NEW_TRAIN_IMG_DIR))\n",
    "new_val_len = len(os.listdir(NEW_VAL_IMG_DIR))\n",
    "new_train_len, new_val_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks correct! Now let's load the original labels and split them for train and validation partition as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11971"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: replace the string below with the path to labels for split module\n",
    "OG_LABEL = '/Users/longhoang/Developer/table-recognition/data/SciTSR/train/label/split_label.json'\n",
    "\n",
    "with open(OG_LABEL, 'r') as f:\n",
    "    labels = json.load(f)\n",
    "    \n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_TRAIN_LABEL = os.path.join(NEW_SCITSR_TRAIN, 'label', 'split_label.json')\n",
    "train_labels = {}\n",
    "\n",
    "for img_path in train_imgs_paths:\n",
    "    img_name = img_name_from_path(img_path)\n",
    "    train_labels[img_name] = labels[img_name]\n",
    "\n",
    "with open(NEW_TRAIN_LABEL, 'w') as f:\n",
    "    json.dump(train_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test correctness\n",
    "with open(NEW_TRAIN_LABEL, 'r') as f:\n",
    "    data = json.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_VAL_LABEL = os.path.join(NEW_SCITSR_VAL, 'label', 'split_label.json')\n",
    "val_labels = {}\n",
    "\n",
    "for img_path in val_imgs_paths:\n",
    "    img_name = img_name_from_path(img_path)\n",
    "    val_labels[img_name] = labels[img_name]\n",
    "\n",
    "with open(NEW_VAL_LABEL, 'w') as f:\n",
    "    json.dump(val_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1971"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test correctness\n",
    "with open(NEW_VAL_LABEL, 'r') as f:\n",
    "    data = json.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-tut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
