{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from split import train\n",
    "from modules.split_modules import SplitModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path đến pretrained weights\n",
    "MODEL_WEIGHT = '/home/hoanghuuson/table_recognition/scitsr-split-train/result/resultCP_v2.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test tren dataset nho\n",
    "train_img_dir = '/home/hoanghuuson/table_recognition/scitsr-split-train-small/train/img'\n",
    "train_json_label = '/home/hoanghuuson/table_recognition/scitsr-split-train-small/train/label/split-label.json'\n",
    "val_img_dir = '/home/hoanghuuson/table_recognition/scitsr-split-train-small/val/img'\n",
    "val_json_label = '/home/hoanghuuson/table_recognition/scitsr-split-train-small/val/label/split-label.json'\n",
    "save_dir = '/home/hoanghuuson/table_recognition/scitsr-split-train-small/result'\n",
    "pred_dir = '/home/hoanghuuson/table_recognition/scitsr-split-train-small/imgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataset lớn a để vào đây và comment cái cell trên lại r chạy bthg\n",
    "# train_img_dir = ''\n",
    "# train_json_label = ''\n",
    "# val_img_dir = '/home/hoanghuuson/table_recognition/scitsr-split-train-small/val/img'\n",
    "# val_json_label = '/home/hoanghuuson/table_recognition/scitsr-split-train-small/val/label/split-label.json'\n",
    "# save_dir = '/home/hoanghuuson/table_recognition/scitsr-split-train-small/result'\n",
    "# pred_dir = '/home/hoanghuuson/table_recognition/scitsr-split-train-small/imgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, train_img_dir, train_json_label, val_img_dir, val_json_label, save_dir,\n",
    "                 batch_size=1, epochs=50, gpu=True, gpu_list='0', lr=0.00075,\n",
    "                 featureW=8, scale=0.5):\n",
    "        self.img_dir = train_img_dir\n",
    "        self.json_dir = train_json_label\n",
    "        self.saved_dir = save_dir\n",
    "        self.val_img_dir = val_img_dir\n",
    "        self.val_json = val_json_label\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.gpu = gpu\n",
    "        self.gpu_list = gpu_list\n",
    "        self.lr = lr\n",
    "        self.featureW = featureW\n",
    "        self.scale = scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "epoch:1\n",
      "Epoch finished ! Loss: 2.0415115356445312 , Accuracy: 0.9655120651480467\n",
      "Validation finished ! Loss: 2.3718886375427246 , Accuracy: 0.958204094292804\n",
      "Saved prediction image at /home/hoanghuuson/table_recognition/scitsr-split-train-small/imgs/split_pred_0_epoch_0.png\n",
      "epoch:2\n",
      "Epoch finished ! Loss: 1.7513444423675537 , Accuracy: 0.9700529140240928\n",
      "Validation finished ! Loss: 2.365770101547241 , Accuracy: 0.9594447890818859\n",
      "Saved prediction image at /home/hoanghuuson/table_recognition/scitsr-split-train-small/imgs/split_pred_0_epoch_1.png\n",
      "epoch:3\n",
      "Epoch finished ! Loss: 1.667456865310669 , Accuracy: 0.9709535782639697\n",
      "Validation finished ! Loss: 2.469648599624634 , Accuracy: 0.9588244416873449\n",
      "Saved prediction image at /home/hoanghuuson/table_recognition/scitsr-split-train-small/imgs/split_pred_0_epoch_2.png\n",
      "epoch:4\n",
      "Epoch finished ! Loss: 1.5529932975769043 , Accuracy: 0.9721544639171389\n",
      "Validation finished ! Loss: 2.5609185695648193 , Accuracy: 0.9569633995037221\n",
      "Saved prediction image at /home/hoanghuuson/table_recognition/scitsr-split-train-small/imgs/split_pred_0_epoch_3.png\n",
      "epoch:5\n",
      "Epoch finished ! Loss: 1.4299595355987549 , Accuracy: 0.9750816226967388\n",
      "Validation finished ! Loss: 2.6344683170318604 , Accuracy: 0.9578939205955335\n",
      "Saved prediction image at /home/hoanghuuson/table_recognition/scitsr-split-train-small/imgs/split_pred_0_epoch_4.png\n",
      "epoch:6\n",
      "Epoch finished ! Loss: 1.3510338068008423 , Accuracy: 0.9767703681465081\n",
      "Validation finished ! Loss: 2.668870449066162 , Accuracy: 0.9576612903225806\n",
      "Saved prediction image at /home/hoanghuuson/table_recognition/scitsr-split-train-small/imgs/split_pred_0_epoch_5.png\n",
      "epoch:7\n",
      "Epoch finished ! Loss: 1.3170373439788818 , Accuracy: 0.9783090028896311\n",
      "Validation finished ! Loss: 2.7601161003112793 , Accuracy: 0.956575682382134\n",
      "Saved prediction image at /home/hoanghuuson/table_recognition/scitsr-split-train-small/imgs/split_pred_0_epoch_6.png\n",
      "epoch:8\n",
      "Epoch finished ! Loss: 1.2464780807495117 , Accuracy: 0.9790220287462004\n",
      "Validation finished ! Loss: 2.776444435119629 , Accuracy: 0.9574286600496278\n",
      "Saved prediction image at /home/hoanghuuson/table_recognition/scitsr-split-train-small/imgs/split_pred_0_epoch_7.png\n",
      "epoch:9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hoanghuuson/table_recognition/code/deep-split-merge-scitsr/run_split_train.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hoanghuuson/table_recognition/code/deep-split-merge-scitsr/run_split_train.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(opt\u001b[39m.\u001b[39msaved_dir):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hoanghuuson/table_recognition/code/deep-split-merge-scitsr/run_split_train.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     os\u001b[39m.\u001b[39mmkdir(opt\u001b[39m.\u001b[39msaved_dir)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hoanghuuson/table_recognition/code/deep-split-merge-scitsr/run_split_train.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m train\u001b[39m.\u001b[39;49mtrain(opt, net, pred_dir)\n",
      "File \u001b[0;32m~/table_recognition/code/deep-split-merge-scitsr/split/train.py:70\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(opt, net, pred_dir, img_id)\u001b[0m\n\u001b[1;32m     67\u001b[0m   optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     68\u001b[0m   times \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     69\u001b[0m   correct_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39msum(\n\u001b[0;32m---> 70\u001b[0m     (pred_label[\u001b[39m0\u001b[39;49m] \u001b[39m>\u001b[39;49m \u001b[39m0.5\u001b[39;49m)\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mIntTensor) \u001b[39m==\u001b[39m label[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mrepeat(times,\n\u001b[1;32m     71\u001b[0m                                                                       \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtype(\n\u001b[1;32m     72\u001b[0m       torch\u001b[39m.\u001b[39mIntTensor))\u001b[39m.\u001b[39mitem() \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39msum(\n\u001b[1;32m     73\u001b[0m     (pred_label[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mIntTensor) \u001b[39m==\u001b[39m label[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mrepeat(times,\n\u001b[1;32m     74\u001b[0m                                                                       \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtype(\n\u001b[1;32m     75\u001b[0m       torch\u001b[39m.\u001b[39mIntTensor))\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     76\u001b[0m   count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m label[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m times \u001b[39m+\u001b[39m label[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msize()[\n\u001b[1;32m     77\u001b[0m     \u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m times\n\u001b[1;32m     78\u001b[0m accuracy \u001b[39m=\u001b[39m correct_count \u001b[39m/\u001b[39m (count)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = Args(train_img_dir, train_json_label, val_img_dir, val_json_label, save_dir)\n",
    "net = SplitModel(3)\n",
    "net = torch.nn.DataParallel(net)\n",
    "net.load_state_dict(torch.load(MODEL_WEIGHT))\n",
    "\n",
    "if opt.gpu:\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = True\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_list\n",
    "    net = net.cuda()\n",
    "\n",
    "if not os.path.exists(opt.saved_dir):\n",
    "    os.mkdir(opt.saved_dir)\n",
    "\n",
    "train.train(opt, net, pred_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 233, 478)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = os.path.join(opt.img_dir, os.listdir(opt.img_dir)[0])\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = np.transpose(img, (2,0,1))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-tut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
