{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCITSR_PATH = '/Users/admin/Developer/table-recognition/data/SciTSR-partition'\n",
    "MODEL_WEIGHT = '/Users/admin/Developer/table-recognition/pret-models/split2.pth'\n",
    "SAVE_PATH = '/Users/admin/Developer/table-recognition/results/stats_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import cv2 as cv\n",
    "\n",
    "from data_utils.utils import *\n",
    "from merge.heuristics import *\n",
    "from dataset.dataset import ImageDataset\n",
    "from modules.split_modules import SplitModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD MODEL\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SplitModel(3)\n",
    "model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    model.load_state_dict(torch.load(MODEL_WEIGHT))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(MODEL_WEIGHT, map_location=torch.device('cpu')))\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def get_split_results(model: SplitModel, \n",
    "                    set_dir: str, \n",
    "                    selected_images=None\n",
    "):\n",
    "    '''\n",
    "    Get split results as a dictionary for further postprocessing or analysis\n",
    "    Args:\n",
    "        model -- Split model\n",
    "        set_dir -- string, path to train, val, or test set\n",
    "    Returns:\n",
    "        res -- dictionary where keys are image names\n",
    "    '''\n",
    "    img_dir = os.path.join(set_dir, 'img')\n",
    "    split_json = os.path.join(set_dir, 'label', 'split_label.json')\n",
    "    \n",
    "    # Load dataset\n",
    "    split_labels = load_json(split_json)\n",
    "    dataset = ImageDataset(img_dir, split_labels, 8, scale=1, min_width=10, returns_image_name=True)\n",
    "    print(f'- Loaded dataset with {len(dataset)} examples')\n",
    "\n",
    "    res = {}\n",
    "    for img, label, name in tqdm(dataset):\n",
    "        if selected_images is not None and name not in selected_images:\n",
    "            continue\n",
    "        # ground truth\n",
    "        r_gt, c_gt = label\n",
    "        r_gt, c_gt = r_gt.cpu().numpy(), c_gt.cpu().numpy() \n",
    "        row_gt_idxs, col_gt_idxs = borders(r_gt), borders(c_gt)\n",
    "        num_rows_gt, num_cols_gt = round(len(row_gt_idxs) / 2), round(len(col_gt_idxs) / 2)\n",
    "\n",
    "        # prediction\n",
    "        r_pred, c_pred = model(img.unsqueeze(0))\n",
    "        r_pred, c_pred = process_split_results(r_pred, c_pred)\n",
    "        r_pred, c_pred = refine_split_results(r_pred), refine_split_results(c_pred)\n",
    "        row_pred_idxs, col_pred_idxs = borders(r_pred), borders(c_pred)\n",
    "        num_rows_pred, num_cols_pred = round(len(row_pred_idxs) / 2), round(len(col_pred_idxs) / 2)\n",
    "\n",
    "        # eval on precision, recall, and f1\n",
    "        r_metrics = eval3(r_pred, r_gt)\n",
    "        c_metrics = eval3(c_pred, c_gt)\n",
    "\n",
    "        # log results\n",
    "        res[name] = {\n",
    "            'num_rows_gt': num_rows_gt,\n",
    "            'num_cols_gt': num_cols_gt,\n",
    "            'num_rows_pred': num_rows_pred,\n",
    "            'num_cols_pred': num_cols_pred,\n",
    "            'row_gt': r_gt.tolist(), 'col_gt': c_gt.tolist(),\n",
    "            'row_pred': r_pred.tolist(), 'col_pred': c_pred.tolist(), \n",
    "            'row_precision': r_metrics['precision'], \n",
    "            'row_recall': r_metrics['recall'], \n",
    "            'row_f1': r_metrics['f1'],\n",
    "            'col_precision': c_metrics['precision'], \n",
    "            'col_recall': c_metrics['recall'], \n",
    "            'col_f1': c_metrics['f1']\n",
    "        }\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded dataset with 1971 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1971/1971 [20:28<00:00,  1.60it/s]  \n"
     ]
    }
   ],
   "source": [
    "# save result on validation set\n",
    "val_res = get_split_results(model, os.path.join(SCITSR_PATH, 'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_csv(results, filepath):\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    fieldnames = ['image_name', 'num_rows_gt', 'num_cols_gt', 'num_rows_pred', 'num_cols_pred',\n",
    "                  'row_gt', 'col_gt', 'row_pred', 'col_pred',\n",
    "                  'row_precision', 'row_recall', 'row_f1',\n",
    "                  'col_precision', 'col_recall', 'col_f1']\n",
    "\n",
    "    with open(filepath, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for image_name, data in results.items():\n",
    "            writer.writerow({'image_name': image_name,\n",
    "                             'num_rows_gt': data['num_rows_gt'],\n",
    "                             'num_cols_gt': data['num_cols_gt'],\n",
    "                             'num_rows_pred': data['num_rows_pred'],\n",
    "                             'num_cols_pred': data['num_cols_pred'],\n",
    "                             'row_gt': data['row_gt'],\n",
    "                             'col_gt': data['col_gt'],\n",
    "                             'row_pred': data['row_pred'],\n",
    "                             'col_pred': data['col_pred'],\n",
    "                             'row_precision': data['row_precision'],\n",
    "                             'row_recall': data['row_recall'],\n",
    "                             'row_f1': data['row_f1'],\n",
    "                             'col_precision': data['col_precision'],\n",
    "                             'col_recall': data['col_recall'],\n",
    "                             'col_f1': data['col_f1']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(val_res, os.path.join(SAVE_PATH, 'val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded dataset with 3000 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [31:45<00:00,  1.57it/s]  \n"
     ]
    }
   ],
   "source": [
    "# save result on test set\n",
    "test_res = get_split_results(model, os.path.join(SCITSR_PATH, 'test'))\n",
    "save_csv(test_res, os.path.join(SAVE_PATH, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded dataset with 3000 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [09:03<00:00,  5.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# save result on test COMP set\n",
    "comp_list = load_txt(os.path.join(SCITSR_PATH, 'SciTSR-COMP.list'))\n",
    "test_comp_res = get_split_results(model, os.path.join(SCITSR_PATH, 'test'), comp_list)\n",
    "save_csv(test_comp_res, os.path.join(SAVE_PATH, 'test_comp.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
